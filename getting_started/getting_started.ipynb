{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# üöÄ Your First AI Creation\n",
    "\n",
    "This is the `getting_started.ipynb` notebook from the **Generative AI API Starter Pack**.\n",
    "\n",
    "This guide is designed for you to get a result in just a few minutes, even if you have no coding experience. We'll use this notebook to:\n",
    "* **Securely** load your API key.\n",
    "* Write a simple command to get your first AI-generated response.\n",
    "* Celebrate your first successful creation!\n",
    "\n",
    "Let's begin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### 1. ‚öôÔ∏è Install Packages\n",
    "\n",
    "The cell below ensures you have the right tools installed for your API to work. All you need to do is just **click it** and **run it**.  \n",
    "\n",
    "To Run a cell: \n",
    "- Click the cell\n",
    "- Click the \"Run Cell\" button (‚ñ∂Ô∏è) that appears.\n",
    "- You're Done! Now, you're ready for the next step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# If developing locally, set the path to requirements.txt (relative to notebook/script location)\n",
    "# Use the existing variable 'filename' as defined elsewhere in the notebook\n",
    "filename = \"../requirements.txt\"\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    pip_command = f\"pip install -r {filename}\"\n",
    "else:\n",
    "    print(f\"No {filename} found, skipping general installation.\")\n",
    "    print(\"Trying to install openai package directly...\")\n",
    "    pip_command = \"pip install openai\"\n",
    "\n",
    "# Execute the appropriate pip command using IPython's run_line_magic\n",
    "!{pip_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### 2. üîë Securely Add Your API Key\n",
    "\n",
    "Your API key is a password. It is never saved in the notebook itself.\n",
    "\n",
    "- If you are in Colab: Use the üîí \"Secrets\" panel on the left to securely add your key. Name it `OPENAI_API_KEY`.\n",
    "\n",
    "- If you are in Jupyter (locally): Follow the instructions in the `env.examples` to add your API Key to the `.env` file or you will nned to enter it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Checks if the OPENAI_API_KEY environment variable is set\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚úÖ Found API key from environment or Colab Secret!\")\n",
    "else:\n",
    "    # If OPENAI_API_KEY is not found, prompts the user to input it securely\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI API key (input hidden): \")\n",
    "    print(\"‚úÖ API key set securely for this session!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### 3. ‚úçÔ∏è Write Your First Prompt\n",
    "\n",
    "Now for the fun part! Write your request for the AI below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change the text inside the quotes to make your own request.\n",
    "my_prompt = (\n",
    "    \"Generate a short, funny story about a robot who discovers a love for gardening.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 4. üß† Get a Response from the AI\n",
    "\n",
    "This cell will send your prompt to the AI and get a response. Just run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below is the API interface that talks to the AI service. Don't worry about the details!\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client with the Harvard API Portal base url and your API key\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    base_url=os.environ.get(\n",
    "        \"OPENAI_BASE_URL\",\n",
    "        \"https://go.apis.huit.harvard.edu/ais-openai-direct-limited-schools/v1\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Create a chat completion with a system prompt using the \"gpt-4\" model.\n",
    "# There are other models available, such as \"gpt-3.5-turbo\" or \"gpt-4\" which\n",
    "# may have different strengths (i.e. speed, cost, capabilities) for your use case.\n",
    "# See the 'Resources' section below for more information on models and APIs.\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\", messages=[{\"role\": \"user\", \"content\": my_prompt}]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Success! You have received a response from the AI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 5. üéâ See the Result!\n",
    "\n",
    "Run the next to see what the AI generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will show the AI-generated story.\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### 6. Add More Power: Prompts and Paramaters \n",
    "\n",
    "Congratulations, you've successfully completed your first AI creation!\n",
    "\n",
    "Now that you've mastered the basics of using an API, lets try two more activites that make using APIs really powerful:\n",
    "- Using System Prompts\n",
    "- Changing API Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### A. üìù Add a \"System Prompt\" (Make Your ChatBot)\n",
    "\n",
    "Congratulations, you've successfully completed your first AI creation!  Let's just right into something else fun. Let's make a ChatBot using system prompts.\n",
    "\n",
    "System prompts are like master instructions that tell the AI **how to behave** before you ask a question! This is a simple but powerful technique to guide the AI for better results. \n",
    "\n",
    "This is the foundation of **prompt engineering**. See the [Resources]() for more resources on prompt engineering. \n",
    "\n",
    "><br>    \n",
    "> <h4>Example: Choice the 'Profession' of your ChatBot</h4>\n",
    "> \n",
    "> A great example of a system prompt where changing even a a single keyword gives vastly different results \n",
    "> \n",
    "> \"You are a helpful assistant who always answers as a [profession].\"\n",
    "> \n",
    "> For example, if you change [profession] to \"doctor\", \"pirate\", \"stand-up comedian\", or \"Shakespearean > actor\", the AI's answers to the same user question will be completely different in tone, style, and content.\n",
    "> \n",
    "> Try changing the profession in the `system_prompt` below.\n",
    ">\n",
    ">  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# The system prompt sets the tone and rules for the AI's response.\n",
    "# You can change the text inside the quotes to give the AI any role you want!\n",
    "system_prompt = \"You are a helpful assistant who always answers as a doctor.\"\n",
    "\n",
    "# This is the user's question, which the AI will respond to.\n",
    "user_question = \"Explain how a volcano erupts.\"\n",
    "\n",
    "# This is the main API call that sends your prompts to the AI model.\n",
    "# We shouldn't need to change anything here because it's already set up to use the system prompt.\n",
    "response = client.chat.completions.create(\n",
    "    # 'model' specifies which AI model you want to use.\n",
    "    # For example, you can choose from various models like \"gpt-3.5-turbo\" or \"gpt-4\".\n",
    "    # Different models have different capabilities (i.e. speed, cost, performance), and some.\n",
    "    # may be better suited for certain tasks than others.\n",
    "    # To learn more about the available models, see the 'OpenAI Models' link in the 'Resources' section below.\n",
    "    model=\"gpt-4\",\n",
    "    # 'messages' is the list of prompts you are sending to the AI.\n",
    "    # The system prompt comes first, followed by the user's question.\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_question},\n",
    "    ],\n",
    ")\n",
    "\n",
    "# This final line prints the AI's response to your screen.\n",
    "print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### B. üé® Adjust Parameters\n",
    "\n",
    "You can fine-tune the AI's responses by changing the parameter settings. For example, these parameters allow you to control **creativity** and **response length**.\n",
    "\n",
    "* **`temperature`**: This controls the creativity or randomness of the output.\n",
    "    * Lower values (e.g., 0.2) make the response more predictable and focused.\n",
    "    * Higher values (e.g., 0.8) make the response more surprising and varied.\n",
    "    * For OpenAI models, a good starting point is 0.5.\n",
    "    * To learnmore about selecting the best tempatures for your use case, see:\n",
    "      * The **Tempature Cheat Sheet** in the [Resources](#resources) section below.\n",
    "  \n",
    "* **`max_completion_tokens`**: This sets a hard limit on the length of the response, which is useful for controlling cost and response size.\n",
    "    * A higher value allows for a longe response, while a lower value keeps it brief.\n",
    "    * The maximum value depends on the model you are using. For example, \"gpt-3.5-turbo\" has a max of 4096 tokens, while \"gpt-4\" can handle up to 8192 tokens.\n",
    "    * A good starting point for many applications is 150 tokens. You can adjust this based on your needs.\n",
    "\n",
    "You can learn more in the official [OpenAI Chat Completions Parameters documentation](https://platform.openai.com/docs/api-reference/chat/create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- You can adjust these settings to fine-tune the AI's response ---\n",
    "\n",
    "# 'temperature' controls creativity. \n",
    "# A higher value makes the AI's response more random.\n",
    "# A lower value makes it more focused and deterministic.\n",
    "# For OpenAI models, a good starting point is 0.5.\n",
    "temperature = 0.5\n",
    "\n",
    "# 'max_tokens' sets a limit on the length of the response.\n",
    "# A higher value allows for a longer response, while a lower value keeps it brief.\n",
    "# The maximum value depends on the model you are using.\n",
    "# For this example, let's start at 150 tokens. You can adjust this based on your needs.\n",
    "max_tokens = 150\n",
    "\n",
    "# The system prompt sets the tone and rules for the AI's response.\n",
    "# You can change the text inside the quotes to give the AI any role you want!\n",
    "system_prompt = \"You are a helpful assistant who always answers as a doctor.\"\n",
    "\n",
    "# This is the user's question, which the AI will respond to.\n",
    "# Feel free to try different questions!\n",
    "user_question = \"Explain how a volcano erupts.\"\n",
    "\n",
    "# This is the main API call, now with the added parameters.\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_question},\n",
    "    ],\n",
    "    # 'temperature' and 'max_tokens' are the optional parameters you can adjust.\n",
    "    temperature=temperature,\n",
    "    max_tokens=max_tokens,\n",
    ")\n",
    "\n",
    "# This prints the AI's response to your screen.\n",
    "print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### 7. What's Next?\n",
    "\n",
    "You now have experience with some powerful features of the OpenAI API! With the tips and resources below, you are on a great path to building apps, tools, and experiments with the power of Generative AI! Happy building!\n",
    "\n",
    "##### **Tip: Jupyter & Colab Basics**\n",
    "Here are some quick tips to help your navigate your notebook even more quickly.\n",
    "- ‚ñ∂Ô∏è **Run a cell:** Click the play button at the left of the cell, or press `Shift + Enter`\n",
    "- ‚ûï **Add a new cell:** Click \"+ Code\" or \"+ Text\" at the top, or press `Ctrl + M` then `B`\n",
    "- ‚úèÔ∏è **Edit a cell:** Just click inside and start typing\n",
    "- üîÑ **Rerun a cell:** Click it again and press `Shift + Enter`\n",
    "- üìù **Change cell type:** Use the dropdown at the top (Code or Markdown/Text)\n",
    "- üóëÔ∏è **Delete a cell:** Select the cell, then click the trash can icon or press `Ctrl + M` then `D`\n",
    "- üíæ **Save notebook:** File ‚Üí Save, or press `Ctrl + S`\n",
    "- üîÅ **Restart the notebook:** Runtime ‚Üí Restart runtime/Restart & Run all (useful if things get stuck!)\n",
    "\n",
    "##### **Resources**\n",
    "Here are some useful resources that developers (like you) appreciate as they build and applications.  \n",
    "- Learn more about OpenAI API:\n",
    "  - [OpenAI Official Documenation](https://platform.openai.com/docs/overview)\n",
    "    - [OpenAI Models](https://platform.openai.com/docs/models)\n",
    "  - [OpenAI Cookbooks](https://cookbook.openai.com/about)\n",
    "  - [Temperature Cheat Sheet (OpenAI Developer Community)](https://community.openai.com/t/cheat-sheet-mastering-temperature-and-top-p-in-chatgpt-api/172683)\n",
    "- Learn more about Prompt Engineering:\n",
    "  - [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)\n",
    "  - [Harvard: Getting started with prompts for text-based Generative AI tools](https://www.huit.harvard.edu/news/ai-prompts)\n",
    "  - [Harvard: System Prompt Library](https://github.com/ncwilson78/System-Prompt-Library)\n",
    "  - [Harvard: Teaching Effectively with ChatGPT Prompts](https://docs.google.com/document/d/1EJTKJ1sKcNAV_TnPcklKHB9-BaCeojNMUJeOJGLgPyY/edit?tab=t.0#heading=h.cv1kxhgzmhkc)\n",
    "-  GitHub: Learn how to share your code\n",
    "  - [Github: Start Your Journey](https://docs.github.com/en/get-started/start-your-journey)\n",
    "- Develop in Colab:\n",
    "  - [Welcome to Colab](https://colab.research.google.com/?hl=en-GB)\n",
    "  - [Python Tutorial With Google Colab](https://colab.research.google.com/github/cs231n/cs231n.github.io/blob/master/python-colab.ipynb)\n",
    "- Develop Locally: \n",
    "  - [Getting Started with VS Code](https://code.visualstudio.com/docs/introvideos/basics)\n",
    "  - [Getting Started with Python in VS Code](https://www.youtube.com/watch?v=D2cwvpJSBX4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
