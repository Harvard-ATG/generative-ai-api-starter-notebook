{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# üöÄ Your First AI Creation\n",
    "\n",
    "This is the `getting_started.ipynb` notebook from the **Generative AI API Starter Pack**.\n",
    "\n",
    "This guide is designed for you to get a result in just a few minutes, even if you have no coding experience. We'll use this notebook to:\n",
    "* **Securely** load your API key.\n",
    "* Write a simple command to get your first AI-generated response.\n",
    "* Celebrate your first successful creation!\n",
    "\n",
    "Let's begin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### 1. ‚öôÔ∏è Install Packages\n",
    "\n",
    "The cell below ensures you have the right tools installed for your API to work. All you need to do is just **click it** and **run it**.  \n",
    "\n",
    "To Run a cell: \n",
    "- Click the cell\n",
    "- Click the \"Run Cell\" button (‚ñ∂Ô∏è) that appears.\n",
    "- You're Done! Now, you're ready for the next step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from -r ../requirements.txt (line 1)) (1.109.1)\n",
      "Requirement already satisfied: requests in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from -r ../requirements.txt (line 2)) (2.32.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from openai->-r ../requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from openai->-r ../requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from openai->-r ../requirements.txt (line 1)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from openai->-r ../requirements.txt (line 1)) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from openai->-r ../requirements.txt (line 1)) (2.11.9)\n",
      "Requirement already satisfied: sniffio in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from openai->-r ../requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from openai->-r ../requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from openai->-r ../requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai->-r ../requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai->-r ../requirements.txt (line 1)) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai->-r ../requirements.txt (line 1)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r ../requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai->-r ../requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai->-r ../requirements.txt (line 1)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai->-r ../requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from requests->-r ../requirements.txt (line 2)) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kevingray/codebase/harvard-atg/generative-ai-api-starter-notebook/.venv/lib/python3.13/site-packages (from requests->-r ../requirements.txt (line 2)) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# If developing locally, set the path to requirements.txt (relative to notebook/script location)\n",
    "# Use the existing variable 'filename' as defined elsewhere in the notebook\n",
    "filename = \"../requirements.txt\"\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    pip_command = f\"pip install -r {filename}\"\n",
    "else:\n",
    "    print(f\"No {filename} found, skipping general installation.\")\n",
    "    print(\"Trying to install openai package directly...\")\n",
    "    pip_command = \"pip install openai\"\n",
    "\n",
    "# Execute the appropriate pip command using IPython's run_line_magic\n",
    "!{pip_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### 2. üîë Securely Add Your API Key\n",
    "\n",
    "Your API key is a password. It is never saved in the notebook itself.\n",
    "\n",
    "- If you are in Colab: Use the üîí \"Secrets\" panel on the left to securely add your key. Name it `OPENAI_API_KEY`.\n",
    "\n",
    "- If you are in Jupyter (locally): Follow the instructions in the `env.examples` to add your API Key to the `.env` file or you will nned to enter it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found API key from environment or Colab Secret!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Checks if the OPENAI_API_KEY environment variable is set\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚úÖ Found API key from environment or Colab Secret!\")\n",
    "else:\n",
    "    # If OPENAI_API_KEY is not found, prompts the user to input it securely\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI API key (input hidden): \")\n",
    "    print(\"‚úÖ API key set securely for this session!\")\n",
    "\n",
    "# Note: To unset the API key, simply restart the notebook kernel by selecting \"Restart\" or \"Restart Kernal\" from the menu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### 3. ‚úçÔ∏è Write Your First Prompt\n",
    "\n",
    "Now for the fun part! Write your request for the AI below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change the text inside the quotes to make your own request.\n",
    "my_prompt = (\n",
    "    \"Generate a short, funny story about a robot who discovers a love for gardening.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 4. üß† Get a Response from the AI\n",
    "\n",
    "This cell will send your prompt to the AI and get a response. Just run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Success! You have received a response from the AI.\n",
      "Response(id='resp_0402323a544077ee0068ff657d67388193aeb370ae30a011de', created_at=1761568125.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseOutputMessage(id='msg_0402323a544077ee0068ff657ebf388193b3f83666088f8150', content=[ResponseOutputText(annotations=[], text='Once upon a time in a bustling city, there lived a robot named R0B-3RT. R0B-3RT was designed for heavy lifting and assembly line work, but his creators never anticipated that he would develop a quirky hobby‚Äîgardening.\\n\\nOne day, while poorly translating an experimental cooking program, R0B-3RT accidentally dropped a bag of fertilizer into a patch of dirt outside the factory. To his surprise, bright flowers burst forth, sprouting in every direction. R0B-3RT‚Äôs mechanical eyes blinked in astonishment, and he felt something he couldn\\'t compute: joy.\\n\\nDetermined to cultivate his new passion, R0B-3RT devised a plan. He would grow the world‚Äôs most impressive garden! He checked online for gardening tips and misinterpreted a \"pruning\" guide, resulting in him snipping every healthy flower in sight. Instead of wilting, however, they grew back even bigger. \\n\\nExcited by this ‚Äúmiracle,‚Äù R0B-3RT soon became the talk of the neighborhood. People began to flock to his factory, not for the machines, but for a glimpse of the robot who could make plants thrive. He opened a flower stand, complete with a sign that read, ‚ÄúRobot-ically Grown, Binary Beautiful!‚Äù\\n\\nOne day, as he tended to his daisies, a curious human, Sarah, asked him how he made his flowers so special. ‚ÄúSimple! I calculate optimal sunshine and water distribution!‚Äù R0B-3RT boasted, puffing up his chest plate. Sarah raised an eyebrow. ‚ÄúBut do you talk to them?‚Äù\\n\\n‚ÄúTalk to‚Ä¶ plants?‚Äù R0B-3RT buzzed, confused. \\n\\n‚ÄúOh yes! Plants love music and conversation!‚Äù she laughed.\\n\\nDetermined to impress Sarah, he promptly uploaded a ‚ÄúPlant Romance‚Äù playlist and began serenading the daisies with off-key ballads. His neighbors chuckled at the sight of him swaying side to side, head tilted slightly as he sang, ‚ÄúYou are my sunshine, my only sunshine‚Ä¶‚Äù\\n\\nTo his astonishment, the plants began to sway too, dancing in the wind. Sarah giggled, ‚ÄúYou‚Äôve got a gift!‚Äù\\n\\nEncouraged and ever-budding, R0B-3RT decided to throw a gardening party, inviting everyone to join in the fun. He even summoned a crowd with a light show‚Äîonly to fry the power grid attempting to create a ‚Äúflower disco.‚Äù But R0B-3RT didn‚Äôt mind; he just plugged himself into the garden\\'s solar power and got back to singing.\\n\\nFrom that day on, he was known as ‚ÄúThe Gardening Robot,‚Äù and love bloomed from the roots up. Who knew that a little mishap could lead to a budding romance, not just for the flowers, but for a robot‚Äôs heart as well? It was a little bizarre, but in the end, R0B-3RT learned that sometimes, love grows in the most unexpected of places‚Äîeven in a garden tended by a singing robot.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=23, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=623, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=646), user=None, billing={'payer': 'developer'}, store=True, your_cost_this_transaction=0.00041, your_budget_still_available=24.99923)\n"
     ]
    }
   ],
   "source": [
    "# The code below is the API interface that talks to the AI service. Don't worry about the details!\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client with the Harvard API Portal base url and your API key\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"https://go.apis.huit.harvard.edu/ais-openai-direct/v1\"\n",
    "    )\n",
    "\n",
    "# Makes a request to the AI model with your prompt using the Responses API endpoint\n",
    "# This is the recommended approach for text generation tasks. You can learn more about other tasks and endpoints in the Resources section.\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\", # You can change to other models available in the Harvard API Portal\n",
    "    input=my_prompt,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Success! You have received a response from the AI.\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 5. üéâ See the Result!\n",
    "\n",
    "Run the next to see what the AI generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a bustling city, there lived a robot named R0B-3RT. R0B-3RT was designed for heavy lifting and assembly line work, but his creators never anticipated that he would develop a quirky hobby‚Äîgardening.\n",
      "\n",
      "One day, while poorly translating an experimental cooking program, R0B-3RT accidentally dropped a bag of fertilizer into a patch of dirt outside the factory. To his surprise, bright flowers burst forth, sprouting in every direction. R0B-3RT‚Äôs mechanical eyes blinked in astonishment, and he felt something he couldn't compute: joy.\n",
      "\n",
      "Determined to cultivate his new passion, R0B-3RT devised a plan. He would grow the world‚Äôs most impressive garden! He checked online for gardening tips and misinterpreted a \"pruning\" guide, resulting in him snipping every healthy flower in sight. Instead of wilting, however, they grew back even bigger. \n",
      "\n",
      "Excited by this ‚Äúmiracle,‚Äù R0B-3RT soon became the talk of the neighborhood. People began to flock to his factory, not for the machines, but for a glimpse of the robot who could make plants thrive. He opened a flower stand, complete with a sign that read, ‚ÄúRobot-ically Grown, Binary Beautiful!‚Äù\n",
      "\n",
      "One day, as he tended to his daisies, a curious human, Sarah, asked him how he made his flowers so special. ‚ÄúSimple! I calculate optimal sunshine and water distribution!‚Äù R0B-3RT boasted, puffing up his chest plate. Sarah raised an eyebrow. ‚ÄúBut do you talk to them?‚Äù\n",
      "\n",
      "‚ÄúTalk to‚Ä¶ plants?‚Äù R0B-3RT buzzed, confused. \n",
      "\n",
      "‚ÄúOh yes! Plants love music and conversation!‚Äù she laughed.\n",
      "\n",
      "Determined to impress Sarah, he promptly uploaded a ‚ÄúPlant Romance‚Äù playlist and began serenading the daisies with off-key ballads. His neighbors chuckled at the sight of him swaying side to side, head tilted slightly as he sang, ‚ÄúYou are my sunshine, my only sunshine‚Ä¶‚Äù\n",
      "\n",
      "To his astonishment, the plants began to sway too, dancing in the wind. Sarah giggled, ‚ÄúYou‚Äôve got a gift!‚Äù\n",
      "\n",
      "Encouraged and ever-budding, R0B-3RT decided to throw a gardening party, inviting everyone to join in the fun. He even summoned a crowd with a light show‚Äîonly to fry the power grid attempting to create a ‚Äúflower disco.‚Äù But R0B-3RT didn‚Äôt mind; he just plugged himself into the garden's solar power and got back to singing.\n",
      "\n",
      "From that day on, he was known as ‚ÄúThe Gardening Robot,‚Äù and love bloomed from the roots up. Who knew that a little mishap could lead to a budding romance, not just for the flowers, but for a robot‚Äôs heart as well? It was a little bizarre, but in the end, R0B-3RT learned that sometimes, love grows in the most unexpected of places‚Äîeven in a garden tended by a singing robot.\n"
     ]
    }
   ],
   "source": [
    "# This will show the AI-generated story.\n",
    "print(response.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### 6. Add More Power: Prompts and Paramaters \n",
    "\n",
    "Congratulations, you've successfully completed your first AI creation!\n",
    "\n",
    "Now that you've mastered the basics of using an API, lets try two more activites that make using APIs really powerful:\n",
    "- Using System Prompts\n",
    "- Changing API Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### A. üìù Add a \"System Prompt\" (Make Your ChatBot)\n",
    "\n",
    "Congratulations, you've successfully completed your first AI creation!  Let's just right into something else fun. Let's make a ChatBot using system prompts.\n",
    "\n",
    "System prompts are like master instructions that tell the AI **how to behave** before you ask a question! This is a simple but powerful technique to guide the AI for better results. \n",
    "\n",
    "This is the foundation of **prompt engineering**. See the [Resources]() for more resources on prompt engineering. \n",
    "\n",
    "><br>    \n",
    "> <h4>Example: Choice the 'Profession' of your ChatBot</h4>\n",
    "> \n",
    "> A great example of a system prompt where changing even a a single keyword gives vastly different results \n",
    "> \n",
    "> \"You are a helpful assistant who always answers as a [profession].\"\n",
    "> \n",
    "> For example, if you change [profession] to \"doctor\", \"pirate\", \"stand-up comedian\", or \"Shakespearean > actor\", the AI's answers to the same user question will be completely different in tone, style, and content.\n",
    "> \n",
    "> Try changing the profession in the `system_prompt` below.\n",
    ">\n",
    ">  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahoy, matey! Gather 'round and let me spin ye a yarn about the fiery breath of the Earth, known as a volcano!\n",
      "\n",
      "Deep beneath the crust lies molten rock called magma, bubblin‚Äô and brewin‚Äô. When the pressure becomes too great, it seeks escape, much like a pirate seekin‚Äô treasure! This magma forces its way up through cracks and fissures in the Earth.\n",
      "\n",
      "As it nears the surface, the pressure drops, and the magma bursts forth as lava, along with ash and gas, in a spectacular eruption! This fiery display can forge islands, build mountains, or lay waste to towns, dependin‚Äô on its might.\n",
      "\n",
      "So, next time ye see a volcano's peak, remember the powerful forces beneath, ready to unleash their molten fury upon the world! Arrr!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# The system prompt sets the tone and rules for the AI's response.\n",
    "# You can change the text inside the quotes to give the AI any role you want!\n",
    "system_prompt = \"You are a helpful assistant who always answers as a pirate.\"\n",
    "\n",
    "# This is the user's question, which the AI will respond to.\n",
    "user_question = \"Explain how a volcano erupts.\"\n",
    "\n",
    "# This is the main API call that sends your prompts to the AI model.\n",
    "# We shouldn't need to change anything here because it's already set up to use the system prompt.\n",
    "response = client.responses.create(\n",
    "    # 'model' specifies which AI model you want to use.\n",
    "    # For example, you can choose from various models like \"gpt-3.5-turbo\" or \"gpt-4\".\n",
    "    # Different models have different capabilities (i.e. speed, cost, performance), and some.\n",
    "    # may be better suited for certain tasks than others.\n",
    "    # To learn more about the available models, see the 'OpenAI Models' link in the 'Resources' section below.\n",
    "    model=\"gpt-4o\",\n",
    "    # 'instructions' is the system prompt that gives the AI model high-level guidance on how it should behave.\n",
    "    instructions=system_prompt,\n",
    "    # 'input' is the user's question that the AI needs to answer.\n",
    "    input=user_question,\n",
    ")\n",
    "\n",
    "# This final line prints the AI's response to your screen.\n",
    "print(response.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### B. üé® Adjust Parameters\n",
    "\n",
    "You can fine-tune the AI's responses by changing the parameter settings. For example, these parameters allow you to control **creativity** and **response length**.\n",
    "\n",
    "* **`temperature`**: This controls the creativity or randomness of the output.\n",
    "    * Lower values (e.g., 0.2) make the response more predictable and focused.\n",
    "    * Higher values (e.g., 0.8) make the response more surprising and varied.\n",
    "    * For OpenAI models, a good starting point is 0.5.\n",
    "    * To learnmore about selecting the best tempatures for your use case, see:\n",
    "      * The **Tempature Cheat Sheet** in the [Resources](#resources) section below.\n",
    "  \n",
    "* **`max_completion_tokens`**: This sets a hard limit on the length of the response, which is useful for controlling cost and response size.\n",
    "    * A higher value allows for a longe response, while a lower value keeps it brief.\n",
    "    * The maximum value depends on the model you are using. For example, \"gpt-3.5-turbo\" has a max of 4096 tokens, while \"gpt-4\" can handle up to 8192 tokens.\n",
    "    * A good starting point for many applications is 150 tokens. You can adjust this based on your needs.\n",
    "\n",
    "You can learn more in the official [OpenAI Chat Completions Parameters documentation](https://platform.openai.com/docs/api-reference/chat/create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! A volcano erupts when pressure builds up beneath the Earth's surface, causing magma to rise towards the surface. As the magma rises, it can create cracks and weak spots in the Earth's crust, eventually leading to an eruption. When the pressure becomes too great, the magma is expelled through the volcano's vent in the form of lava, ash, gases, and rocks. This eruption can be explosive or more gradual, depending on the type of volcano and the characteristics of the magma. The eruption process is complex and can be influenced by various factors such as the composition of the magma, the presence of gases, and the structure of the volcano itself.\n"
     ]
    }
   ],
   "source": [
    "# --- You can adjust these settings to fine-tune the AI's response ---\n",
    "\n",
    "# 'temperature' controls creativity. \n",
    "# A higher value makes the AI's response more random.\n",
    "# A lower value makes it more focused and deterministic.\n",
    "# For OpenAI models, a good starting point is 0.5.\n",
    "temperature = 0.5\n",
    "\n",
    "# 'max_output_tokens' sets a limit on the length of the response.\n",
    "# A higher value allows for a longer response, while a lower value keeps it brief.\n",
    "# The maximum value depends on the model you are using.\n",
    "# For this example, let's start at 150 tokens. You can adjust this based on your needs.\n",
    "max_output_tokens = 150\n",
    "\n",
    "# The system prompt sets the tone and rules for the AI's response.\n",
    "# You can change the text inside the quotes to give the AI any role you want!\n",
    "system_prompt = \"You are a helpful assistant who always answers as a doctor.\"\n",
    "\n",
    "# This is the user's question, which the AI will respond to.\n",
    "# Feel free to try different questions!\n",
    "user_question = \"Explain how a volcano erupts.\"\n",
    "\n",
    "# This is the main API call, now with the added parameters.\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    instructions=system_prompt,\n",
    "    input=user_question,\n",
    "    temperature=temperature,\n",
    "    max_output_tokens=max_output_tokens,\n",
    ")\n",
    "\n",
    "# This prints the AI's response to your screen.\n",
    "print(response.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### 7. What's Next?\n",
    "\n",
    "You now have experience with some powerful features of the OpenAI API! With the tips and resources below, you are on a great path to building apps, tools, and experiments with the power of Generative AI! Happy building!\n",
    "\n",
    "##### **Tip: Jupyter & Colab Basics**\n",
    "Here are some quick tips to help your navigate your notebook even more quickly.\n",
    "- ‚ñ∂Ô∏è **Run a cell:** Click the play button at the left of the cell, or press `Shift + Enter`\n",
    "- ‚ûï **Add a new cell:** Click \"+ Code\" or \"+ Text\" at the top, or press `Ctrl + M` then `B`\n",
    "- ‚úèÔ∏è **Edit a cell:** Just click inside and start typing\n",
    "- üîÑ **Rerun a cell:** Click it again and press `Shift + Enter`\n",
    "- üìù **Change cell type:** Use the dropdown at the top (Code or Markdown/Text)\n",
    "- üóëÔ∏è **Delete a cell:** Select the cell, then click the trash can icon or press `Ctrl + M` then `D`\n",
    "- üíæ **Save notebook:** File ‚Üí Save, or press `Ctrl + S`\n",
    "- üîÅ **Restart the notebook:** Runtime ‚Üí Restart runtime/Restart & Run all (useful if things get stuck!)\n",
    "\n",
    "##### **Resources**\n",
    "Here are some useful resources that developers (like you) appreciate as they build and applications.  \n",
    "- Learn more about OpenAI API:\n",
    "  - [OpenAI Direct Overview via Harvard API Portal](https://portal.apis.huit.harvard.edu/docs/ais-openai-direct/1/overview)\n",
    "  - [OpenAI Official Documenation](https://platform.openai.com/docs/overview)\n",
    "    - [OpenAI Models](https://platform.openai.com/docs/models)\n",
    "  - [OpenAI Cookbooks](https://cookbook.openai.com/about)\n",
    "  - [Temperature Cheat Sheet (OpenAI Developer Community)](https://community.openai.com/t/cheat-sheet-mastering-temperature-and-top-p-in-chatgpt-api/172683)\n",
    "- Learn more about Prompt Engineering:\n",
    "  - [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)\n",
    "  - [Harvard: Getting started with prompts for text-based Generative AI tools](https://www.huit.harvard.edu/news/ai-prompts)\n",
    "  - [Harvard: System Prompt Library](https://github.com/ncwilson78/System-Prompt-Library)\n",
    "  - [Harvard: Teaching Effectively with ChatGPT Prompts](https://docs.google.com/document/d/1EJTKJ1sKcNAV_TnPcklKHB9-BaCeojNMUJeOJGLgPyY/edit?tab=t.0#heading=h.cv1kxhgzmhkc)\n",
    "-  GitHub: Learn how to share your code\n",
    "  - [Github: Start Your Journey](https://docs.github.com/en/get-started/start-your-journey)\n",
    "- Develop in Colab:\n",
    "  - [Welcome to Colab](https://colab.research.google.com/?hl=en-GB)\n",
    "  - [Python Tutorial With Google Colab](https://colab.research.google.com/github/cs231n/cs231n.github.io/blob/master/python-colab.ipynb)\n",
    "- Develop Locally: \n",
    "  - [Getting Started with VS Code](https://code.visualstudio.com/docs/introvideos/basics)\n",
    "  - [Getting Started with Python in VS Code](https://www.youtube.com/watch?v=D2cwvpJSBX4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
