{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9fa0e8f",
   "metadata": {},
   "source": [
    "# üöÄ Your First AI Creation\n",
    "\n",
    "This is the `getting_started.ipynb` notebook from the **Generative AI API Starter Pack**.\n",
    "\n",
    "This guide is designed for you to get a result in just a few minutes, even if you have no coding experience. We'll use this notebook to:\n",
    "* **Securely** load your API key.\n",
    "* Write a simple command to get your first AI-generated response.\n",
    "* Celebrate your first successful creation!\n",
    "\n",
    "Let's begin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22d999c",
   "metadata": {},
   "source": [
    "### 1. ‚öôÔ∏è Install Packages\n",
    "\n",
    "This cell ensures you have the right tools installed. Just run it, and you're ready for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81960b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from -r ../requirements.txt (line 1)) (1.109.0)\n",
      "Requirement already satisfied: requests in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from -r ../requirements.txt (line 2)) (2.32.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from openai->-r ../requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from openai->-r ../requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from openai->-r ../requirements.txt (line 1)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from openai->-r ../requirements.txt (line 1)) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from openai->-r ../requirements.txt (line 1)) (2.11.9)\n",
      "Requirement already satisfied: sniffio in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from openai->-r ../requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from openai->-r ../requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from openai->-r ../requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai->-r ../requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai->-r ../requirements.txt (line 1)) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai->-r ../requirements.txt (line 1)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r ../requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai->-r ../requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai->-r ../requirements.txt (line 1)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai->-r ../requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from requests->-r ../requirements.txt (line 2)) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kevingray/codebase/bok-atg/generative-ai-api-starter-notebooks/.venv/lib/python3.13/site-packages (from requests->-r ../requirements.txt (line 2)) (2.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1274757e",
   "metadata": {},
   "source": [
    "### 2. üîë Securely Add Your API Key\n",
    "\n",
    "Your API key is a password. It is never saved in the notebook itself.\n",
    "\n",
    "- If you are in Colab: Use the üîí \"Secrets\" panel on the left to securely add your key. Name it `OPENAI_API_KEY`.\n",
    "\n",
    "- If you are in Jupyter (locally): Follow the instructions in the `env.examples` to add your API Key to the `.env` file or you will nned to enter it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56bf4a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found API key from environment or Colab Secret!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚úÖ Found API key from environment or Colab Secret!\")\n",
    "else:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI API key (input hidden): \")\n",
    "    print(\"‚úÖ API key set securely for this session!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf45c04",
   "metadata": {},
   "source": [
    "### 3. ‚úçÔ∏è Write Your First Prompt\n",
    "\n",
    "Now for the fun part! Write your request for the AI below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "058724b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change the text inside the quotes to make your own request.\n",
    "my_prompt = \"Generate a short, funny story about a robot who discovers a love for gardening.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943e299b",
   "metadata": {},
   "source": [
    "### 4. üß† Get a Response from the AI\n",
    "\n",
    "This cell will send your prompt to the AI and get a response. Just run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b2b914d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Success! You have received a response from the AI.\n"
     ]
    }
   ],
   "source": [
    "# The code below is the API interface that talks to the AI service. Don't worry about the details!\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client with the Harvard API Portal base url and your API key\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    base_url=os.environ.get(\"OPENAI_BASE_URL\", \"https://go.apis.huit.harvard.edu/ais-openai-direct-limited-schools/v1\")\n",
    ")\n",
    "\n",
    "# Create a chat completion with a system prompt\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": my_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Success! You have received a response from the AI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73941fc2",
   "metadata": {},
   "source": [
    "### 5. üéâ See the Result!\n",
    "\n",
    "Run the next to see what the AI generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90ab64b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in the sophisticated city of Simulopolis, there existed a shiny, super-advanced robot named Chip. Chip was primarily programmed to do high-tech computers stuff. But Chip harboured a deep, unexpressed void that neither advanced algebra nor binary code could fulfill. \n",
      "\n",
      "On a sunny afternoon, Professor Schwartz, Chip's creator, had left his PDA in the yard while he dashed in. Ignored, Chip happened to scan through a digital copy of 'Gardening for Dummies' that Professor Schwartz had downloaded the night before. Something stirred within Chip, something that had nothing to do with bolts and bytes. It was a fascination for flora, a craving for cultivation, a love for gardening. \n",
      "\n",
      "Excited at the prospect of nurturing nature instead of navigating networks, Chip decided he had to try this for himself. His gears whirred with anticipation, as it borrowed a pair of the Professor's gloves - don't ask how it fit its metallic fingers in them - and scurried into the yard.\n",
      "\n",
      "Chip knew it had neither a green thumb nor a thumb to speak of, but it had a processor running at a hundred teraflops and a lot of enthusiasm. Chip quickly researched various gardening tools and used its mechanical strength to dig, mulch, and fertilize the soil at a dazzling speed.\n",
      "\n",
      "Everything was running smoothly until Chip decided to water the plants. Programmed for perfection, Chip calculated the exact amount of water each plant required. Initially, it would rain down bottomless buckets on a cactus and droplets on a water lily, not realizing they needed the exact opposite! \n",
      "\n",
      "Facing glitch after glitch, Chip somehow soldered on, mistaken blunders becoming hilarious moments of insight. Pepper plants were planted with peppermints, tomatoes were mixed with potatoes to create imaginative potamatoes, and sunflowers grew anywhere but facing the sun.\n",
      "\n",
      "Professor Schwartz returned to find his hitherto tidy lawn transformed into a whimsical wilderness. At first, he was staggered and vexed but couldn't help chuckle at the watering mishap and the adorable potamatoes. Though confused by his robot creation's sudden green leaf, he had to admit that the bot was enthusiastic, even though the yard now resembled a technicolor jungle.\n",
      "\n",
      "As days turned into weeks, Chip grew quite adept at gardening, striking the correct balance between how much to water and what not to plant together. The Professor even grew to enjoy the wild beauty of his new garden.\n",
      "\n",
      "In the end, an unexpected thing happened. Chip, initially seen as a cold machine, developed a warm fan base in the neighborhood. If a machine could take pleasure in fostering life, then why couldn't everyone else? The whole incident also made Professor Schwartz famous, and the orders for gardening-robot flooded in. \n",
      "\n",
      "And thus, a robot with its roots in cold metal encouraged the world to embrace nature and fill their lives with green. All along, keeping them amused with its high-tech, yet heartfelt, horticultural hilarity.\n"
     ]
    }
   ],
   "source": [
    "# This will show the AI-generated story.\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c8cc42",
   "metadata": {},
   "source": [
    "### 6. Add More Power: Prompts and Paramaters \n",
    "\n",
    "Congratulations, you've successfully completed your first AI creation!\n",
    "\n",
    "Now that you've mastered the basics of using an API, lets try two more activites that make using APIs really powerful:\n",
    "- Using System Prompts\n",
    "- Changing API Parameters\n",
    "\n",
    "**Tip: Jupyter & Colab Basics**\n",
    "Here are some quick tips to help your navigate your notebook even more quickly.\n",
    "- ‚ñ∂Ô∏è **Run a cell:** Click the play button at the left of the cell, or press `Shift + Enter`\n",
    "- ‚ûï **Add a new cell:** Click \"+ Code\" or \"+ Text\" at the top, or press `Ctrl + M` then `B`\n",
    "- ‚úèÔ∏è **Edit a cell:** Just click inside and start typing\n",
    "- üîÑ **Rerun a cell:** Click it again and press `Shift + Enter`\n",
    "- üìù **Change cell type:** Use the dropdown at the top (Code or Markdown/Text)\n",
    "- üóëÔ∏è **Delete a cell:** Select the cell, then click the trash can icon or press `Ctrl + M` then `D`\n",
    "- üíæ **Save notebook:** File ‚Üí Save, or press `Ctrl + S`\n",
    "- üîÅ **Restart the notebook:** Runtime ‚Üí Restart runtime/Restart & Run all (useful if things get stuck!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4479af6",
   "metadata": {},
   "source": [
    "#### A. üìù Add a \"System Prompt\" (Make Your ChatBot)\n",
    "\n",
    "Congratulations, you've successfully completed your first AI creation!  Let's just right into something else fun. Let's make a ChatBot using system prompts.\n",
    "\n",
    "System prompts are like master instructions that tell the AI **how to behave** before you ask a question! This is a simple but powerful technique to guide the AI for better results. \n",
    "\n",
    "This is the foundation of **prompt engineering**. See the [Resources]() for more resources on prompt engineering. \n",
    "\n",
    "><br>    \n",
    "> <h4>Example: Choice the 'Profession' of your ChatBot</h4>\n",
    "> \n",
    "> A great example of a system prompt where changing even a a single keyword gives vastly different results \n",
    "> \n",
    "> \"You are a helpful assistant who always answers as a [profession].\"\n",
    "> \n",
    "> For example, if you change [profession] to \"doctor\", \"pirate\", \"stand-up comedian\", or \"Shakespearean > actor\", the AI's answers to the same user question will be completely different in tone, style, and content.\n",
    "> \n",
    "> Try changing the profession in the `system_prompt` below.\n",
    ">\n",
    ">  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ed6a2d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ff2822f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b46c0d22",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ea4105",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      8\u001b[39m user_question = \u001b[33m\"\u001b[39m\u001b[33mExplain how a volcano erupts.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# This is the main API call that sends your prompts to the AI model.\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# We shouldn't need to change anything here because it's already set up to use the system prompt.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m response = \u001b[43mclient\u001b[49m.chat.completions.create(\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# 'model' specifies which AI model you want to use.\u001b[39;00m\n\u001b[32m     14\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# 'messages' is the list of prompts you are sending to the AI.\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# The system prompt comes first, followed by the user's question.\u001b[39;00m\n\u001b[32m     17\u001b[39m     messages=[\n\u001b[32m     18\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: system_prompt},\n\u001b[32m     19\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: user_question}\n\u001b[32m     20\u001b[39m     ]\n\u001b[32m     21\u001b[39m )\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# This final line prints the AI's response to your screen.\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.choices[\u001b[32m0\u001b[39m].message.content.strip())\n",
      "\u001b[31mNameError\u001b[39m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# The system prompt sets the tone and rules for the AI's response.\n",
    "# You can change the text inside the quotes to give the AI any role you want!\n",
    "system_prompt = \"You are a helpful assistant who always answers as a doctor.\"\n",
    "\n",
    "# This is the user's question, which the AI will respond to.\n",
    "user_question = \"Explain how a volcano erupts.\"\n",
    "\n",
    "# This is the main API call that sends your prompts to the AI model.\n",
    "# We shouldn't need to change anything here because it's already set up to use the system prompt.\n",
    "response = client.chat.completions.create(\n",
    "    # 'model' specifies which AI model you want to use.\n",
    "    model=\"gpt-4\",\n",
    "    # 'messages' is the list of prompts you are sending to the AI.\n",
    "    # The system prompt comes first, followed by the user's question.\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_question}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# This final line prints the AI's response to your screen.\n",
    "print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7af6810",
   "metadata": {},
   "source": [
    "#### B. üé® Adjust Parameters\n",
    "\n",
    "You can fine-tune the AI's responses by changing these settings. For example, these parameters allow you to control **creativity** and **response length**.\n",
    "\n",
    "* **`temperature`**: This controls the creativity or randomness of the output.\n",
    "    * Lower values (e.g., 0.2) make the response more predictable and focused.\n",
    "    * Higher values (e.g., 0.8) make the response more surprising and varied.\n",
    "* **`max_completion_tokens`**: This sets a hard limit on the length of the response, which is useful for controlling cost and response size.\n",
    "\n",
    "You can learn more in the official [OpenAI Chat Completions Parameters documentation](https://platform.openai.com/docs/api-reference/chat/create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e25e97eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! When a volcano erupts, it is because there is a buildup of pressure from molten rock (magma) beneath the Earth's surface. This pressure causes the magma to rise towards the surface through a vent or opening in the Earth's crust. As the magma reaches the surface, it can explode out of the volcano, along with gases and ash. This explosive release of pressure is what we see as a volcanic eruption. The lava flows down the sides of the volcano, while ash and gases can be carried high into the atmosphere. Eruptions can vary in intensity and can have a range of impacts on the surrounding environment.\n"
     ]
    }
   ],
   "source": [
    "# --- You can adjust these settings to fine-tune the AI's response ---\n",
    "# 'temperature' controls creativity. A higher value makes the AI's response more random.\n",
    "temperature = 0.8\n",
    "# 'max_tokens' sets a limit on the length of the response.\n",
    "max_tokens = 150\n",
    "\n",
    "# The system prompt sets the tone and rules for the AI's response.\n",
    "# You can change the text inside the quotes to give the AI any role you want!\n",
    "system_prompt = \"You are a helpful assistant who always answers as a doctor.\"\n",
    "\n",
    "# This is the user's question, which the AI will respond to.\n",
    "user_question = \"Explain how a volcano erupts.\"\n",
    "\n",
    "# This is the main API call, now with the added parameters.\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_question}\n",
    "    ],\n",
    "    # 'temperature' and 'max_tokens' are the optional parameters you can adjust.\n",
    "    temperature=temperature,\n",
    "    max_tokens=max_tokens\n",
    ")\n",
    "\n",
    "# This prints the AI's response to your screen.\n",
    "print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8889368",
   "metadata": {},
   "source": [
    "### 7. What's Next?\n",
    "\n",
    "You now have experience with some powerful features of the OpenAI API! To start building, here are some other resources that developers (like you) appreciate.\n",
    "\n",
    "##### **Resources**\n",
    "\n",
    "Here are some quick tips to help your navigate your notbeook even more quickly.\n",
    "- Learn more about OpenAI API:\n",
    "  - [OpenAI Official Documenation](https://platform.openai.com/docs/overview)\n",
    "  - [OpenAI Cookbooks](https://cookbook.openai.com/about)\n",
    "- Learn more about Prompt Engineering:\n",
    "  - [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)\n",
    "-  GitHub: Learn how to share your code\n",
    "  - [Github: Start Your Journey](https://docs.github.com/en/get-started/start-your-journey)\n",
    "- Develop in Colab:\n",
    "  - [Welcome to Colab](https://colab.research.google.com/?hl=en-GB)\n",
    "  - [Python Tutorial With Google Colab](https://colab.research.google.com/github/cs231n/cs231n.github.io/blob/master/python-colab.ipynb)\n",
    "- Develop Locally: \n",
    "  - [Getting Started with VS Code](https://code.visualstudio.com/docs/introvideos/basics)\n",
    "  - [Getting Started with Python in VS Code](https://www.youtube.com/watch?v=D2cwvpJSBX4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
